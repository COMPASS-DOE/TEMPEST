---
title: "FeCode_updated2025_inprogress_multiplates"
output: pdf_document
date: "2025-11-20"
---

```{r setup, include=FALSE}
library(dplyr)
library(broom)
library(ggplot2)
library(ggpubr)
library(stringr)
library(purrr)
library(tidyverse)
library(here)
library(data.table)
library(matrixStats)
library(gridExtra)
library(grid)
library(plater)
library(raster)
library(knitr)  
library(readxl)

#take out of sci notation
options(scipen = 999)
setwd("S:/GlobalChangeEco/Porewater_R scripts & Data/Data/Fe/COMPASS")
```

```{r Information to be changed}

###things that need to be changed
Date_Run = "20251118"
plates<- c("Plate1","Plate2")
Std_plates<- c("STD2")
file_name<-"Experiment4_allplates"
Run_by = "Melanie Giessner, Zoe Read"#Instrument user
Script_run_by ="Melanie Giessner"#Code user
Project = "COMPASS"
Experiment="TEMPEST Aquifer Well"
Run_notes=""#any notes from run

#Stds that should be excluded

```

```{r, echo=FALSE}
#read in all the Tidy data files
folder_path_tidydata <- paste0(Experiment,"/Tidy Data")
file_paths_STDs <- list.files(path = folder_path_tidydata, full.names = TRUE,pattern =paste0(Date_Run,".+.STD"))
head(file_paths_STDs)
file_paths_tidydata <- list.files(path = folder_path_tidydata, full.names = TRUE,pattern ="Plate")
head(file_paths_tidydata)

#file path name for processed data
summarizeddata_path=paste0(Experiment,"/QAQC'd Data/GENX2_H2S_",Date_Run,"_",file_name,"_Summary_Data.csv")
fulldata_path=paste0(Experiment,"/QAQC'd Data/GENX2_H2S_",Date_Run,"_",file_name,"_Data.csv")
shortdata_path=paste0(Experiment,"/QAQC'd Data/GENX2_H2S_",Date_Run,"_",file_name,"_short_Data.csv")
Need_dilute=paste0(Experiment,"/QAQC'd Data/GENX2_H2S_",Date_Run,"_",file_name,"_Need_dilute_Data.csv")
high_CV=paste0(Experiment,"/QAQC'd Data/GENX2_H2S_",Date_Run,"_",file_name,"_high_CV_Data.csv")
#QAQC log path
log_path="S:/GlobalChangeEco/porewater_r scripts & Data/BGC_GCE_PorewaterAnalysis/Fe/Fe_STD_QAQC.csv"

```

```{r Set Up Code - constants and QAQC cutoffs, include=FALSE}

#Flag cutoffs
  r2_cutoff = 0.985            #this is the level below which we want to rerun or consider a curve 
  cv_flag_stds = 10           #this is the maximum cv allowed for standards
  p_value_chkstds = 0.05      #the p-value for the t-test between check  and top std must be greater than this
  cv_flag_sample = 10         #this is the maximum cv allowed for samples
  dups_perc_diff = 15.5       #this is the maximum percent difference allowed between duplicates
  high_recovery_cutoff = 120  #this is the maximum percent recovery allowed in spiked samples
  low_recovery_cutoff = 80    #this is the minimum percent recovery allowed in spiked samples

#mdl  
StudentsT <- 2.528 #Identify the proper Student's T for n-1 n=

# Chk Standard concentrations - Update if running different standard curve:
# standard units are in uM


#Spike concentration calc
  #spike for these samples was 55 uL of the 60uM standard
  Con1 <- 1000000               #conversion factor value for spike volumes (uL -> L)
  spk_std <- 60                # uM Fe2- standard used
  spkvol <- 55                  # uL volume of spike added
  spk_Conc <- spk_std*(spkvol/Con1)  # umoles of S2- added to each spiked sample
  sample_vol <- 160             # the sample volume without the spike is 160 uL

#Top standard Concentration- Update if running different standard curve: 
Top_STD_Fe2_low = 60
Top_STD_Fe3_low = 60

Top_STD_Fe2_high = 500
Top_STD_Fe3_high = 100
Top_STD_Fe2_Abs2_high=100

```
## read in Stds
```{r read in Std curves,echo=FALSE,include=FALSE}

#read in the csv files
stds<-read_plates(
  files = file_paths_STDs,#list of all file paths
  plate_names = Std_plates ,  #list of plate names          
  well_ids_column = "Wells",    # name to give column of well IDs (optional)
  sep = ","                     # separator used in the csv file (optional)
) %>%
  rename("Abs1"=values,
         "Abs2"=values.2,
         "IDs"=values.3,
         "Dilution"=values.4,
         "Conc_uM"=values.5)
head(stds)
  
```
## read in Data
```{r read in Data,echo=FALSE,include=FALSE}

#read in the csv files
dat<-read_plates(
  files = file_paths_tidydata,#list of all file paths
  plate_names = plates ,  #list of plate names          
  well_ids_column = "Wells",    # name to give column of well IDs (optional)
  sep = ","                     # separator used in the csv file (optional)
) %>%
  rename("Abs1"=values,
         "Abs2"=values.2,
         "IDs"=values.3,
         "Dilution"=values.4)
str(dat)
head(dat)
dat$QAQC_flag<-""
  
```

##Remove High cv stds
```{r Remove high cv stds,echo=FALSE,fig.keep='none',include=FALSE}

stds_all<- stds
stds_all_fixed<-stds_all
#make a data frame for the averages 
stds1_Abs1_all <- data.frame(matrix(ncol = 8, nrow =0 ))
colnames(stds1_Abs1_all)<-c("IDs", "Abs1_mean", "Abs1_sd", "Abs1_cv", "Dilution", "Conc_uM","Plate", "Abs1_cv_flag")
#make dataframe for fixed data
stds_Abs1_HCV_fixed<-data.frame(matrix(ncol = 8, nrow =0 ))
colnames(stds_Abs1_HCV_fixed)<-c("IDs", "Abs1_mean", "Abs1_sd", "Abs1_cv", "Dilution", "Conc_uM","Plate", "Abs1_cv_flag")

#make a loop for each plate 
for(y in 1:length(Std_plates)){
  # make a new dataframe for the high cv points for each plate
  stds_Abs1_HCV_fixed<-data.frame(matrix(ncol = 8, nrow =0 ))
  colnames(stds_Abs1_HCV_fixed)<-c("IDs", "Abs1_mean", "Abs1_sd", "Abs1_cv", "Dilution", "Conc_uM","Plate", "Abs1_cv_flag")
  
  #filter each plate    
  std_plate<- stds_all %>% subset(Plate == Std_plates[y])
  
  #Calculate cv for STDs
  std_plate1 <- std_plate %>%
    group_by(IDs) %>%
    summarise(Abs1_mean = mean(Abs1), Abs1_sd = sd(Abs1), Abs1_cv = cv(Abs1),
              Dilution = first(Dilution),
              Conc_uM = first(Conc_uM),
              Plate = first(Plate))
  std_plate1$Abs1_cv_flag <- ifelse(std_plate1$Abs1_cv > cv_flag_stds, 'High CV', 'Within range')
  
  
  #add each plate to std average dataframe
  stds1_Abs1_all<-rbind(stds1_Abs1_all,std_plate1)
  # filter High CV Samples
  stds_Abs1_all_HCV <- std_plate1 %>%  
    filter(str_detect(Abs1_cv_flag, "High CV"))
  #this will keep the loop from breaking if there are no high cv points
  if(!nrow(stds_Abs1_all_HCV)==0){  
    
    #make a loop to filter each high cv sample
    for(x in 1:nrow(stds_Abs1_all_HCV)){
      sing_ID<- std_plate %>% subset(IDs == stds_Abs1_all_HCV$IDs[x])
      #make a dataframe for cvs
      cv_trial<-data.frame(matrix(ncol = 3, nrow =1 ))
      
      #make a loop to find the cv for each deleted point
      for(i in 1:nrow(sing_ID)){
        sing_ID1<-sing_ID[-i,] 
        cv_trial[i]<-cv(sing_ID1$Abs1)
      }
      
      # delete the point that gives the lowest cv
      sing_ID<-sing_ID[-which.min(cv_trial),]
      stds_Abs1_HCV_fixed<-rbind(stds_Abs1_HCV_fixed,sing_ID)
    }
    #recalculate the average and cv  
    stds1_Abs1_all_fixed <- stds_Abs1_HCV_fixed %>%
      group_by(IDs) %>%
      summarise(Abs1_mean = mean(Abs1), Abs1_sd = sd(Abs1), Abs1_cv = cv(Abs1),
                Dilution = first(Dilution),
                Conc_uM = first(Conc_uM),
                Plate = first(Plate))
    #Flag high cvs
    stds1_Abs1_all_fixed$Abs1_cv_flag <- ifelse(stds1_Abs1_all_fixed$Abs1_cv > cv_flag_stds, 'High CV', 'Within range')
    #bind fixed dataframes back together with non high cv points
    #averaged stds
    stds1_Abs1_all <- subset(stds1_Abs1_all, (!(IDs %in% stds1_Abs1_all_fixed$IDs & Plate %in% stds1_Abs1_all_fixed$Plate)))
    stds1_Abs1_all <- rbind(stds1_Abs1_all_fixed, stds1_Abs1_all) 
    #all points  
    stds_all_fixed <- subset(stds_all_fixed, (!(IDs %in% stds_Abs1_HCV_fixed$IDs & Plate %in% stds_Abs1_HCV_fixed$Plate)))
    stds_all_fixed <- rbind(stds_Abs1_HCV_fixed, stds_all_fixed) 
  }}

# filter High CV Stds
stds_Abs1_HCV <- stds1_Abs1_all %>%  
  filter(str_detect(Abs1_cv_flag, "High CV")) 
head(stds_Abs1_HCV)
```

```{r Remove high cv stds,echo=FALSE,fig.keep='none',include=FALSE}


#make a data frame for the averages 
stds1_Abs2_all <- data.frame(matrix(ncol = 8, nrow =0 ))
colnames(stds1_Abs2_all)<-c("IDs", "Abs2_mean", "Abs2_sd", "Abs2_cv", "Dilution", "Conc_uM","Plate", "Abs2_cv_flag")
#make dataframe for fixed data
stds_Abs2_HCV_fixed<-data.frame(matrix(ncol = 8, nrow =0 ))
colnames(stds_Abs2_HCV_fixed)<-c("IDs", "Abs2_mean", "Abs2_sd", "Abs2_cv", "Dilution", "Conc_uM","Plate", "Abs2_cv_flag")

#make a loop for each plate 
for(y in 1:length(Std_plates)){
  # make a new dataframe for the high cv points for each plate
  stds_Abs2_HCV_fixed<-data.frame(matrix(ncol = 8, nrow =0 ))
  colnames(stds_Abs2_HCV_fixed)<-c("IDs", "Abs2_mean", "Abs2_sd", "Abs2_cv", "Dilution", "Conc_uM","Plate", "Abs2_cv_flag")
  
  #filter each plate    
  std_plate<- stds_all %>% subset(Plate == Std_plates[y])
  
  #Calculate cv for STDs
  std_plate1 <- std_plate %>%
    group_by(IDs) %>%
    summarise(Abs2_mean = mean(Abs2), Abs2_sd = sd(Abs2), Abs2_cv = cv(Abs2),
              Dilution = first(Dilution),
              Conc_uM = first(Conc_uM),
              Plate = first(Plate))
  std_plate1$Abs2_cv_flag <- ifelse(std_plate1$Abs2_cv > cv_flag_stds, 'High CV', 'Within range')
  
  
  #add each plate to std average dataframe
  stds1_Abs2_all<-rbind(stds1_Abs2_all,std_plate1)
  # filter High CV Samples
  stds_Abs2_all_HCV <- std_plate1 %>%  
    filter(str_detect(Abs2_cv_flag, "High CV"))
  #this will keep the loop from breaking if there are no high cv points
  if(!nrow(stds_Abs2_all_HCV)==0){  
    
    #make a loop to filter each high cv sample
    for(x in 1:nrow(stds_Abs2_all_HCV)){
      sing_ID<- std_plate %>% subset(IDs == stds_Abs2_all_HCV$IDs[x])
      #make a dataframe for cvs
      cv_trial<-data.frame(matrix(ncol = 3, nrow =1 ))
      
      #make a loop to find the cv for each deleted point
      for(i in 1:nrow(sing_ID)){
        sing_ID1<-sing_ID[-i,] 
        cv_trial[i]<-cv(sing_ID1$Abs2)
      }
      
      # delete the point that gives the lowest cv
      sing_ID<-sing_ID[-which.min(cv_trial),]
      stds_Abs2_HCV_fixed<-rbind(stds_Abs2_HCV_fixed,sing_ID)
    }
    #recalculate the average and cv  
    stds1_Abs2_all_fixed <- stds_Abs2_HCV_fixed %>%
      group_by(IDs) %>%
      summarise(Abs2_mean = mean(Abs2), Abs2_sd = sd(Abs2), Abs2_cv = cv(Abs2),
                Dilution = first(Dilution),
                Conc_uM = first(Conc_uM),
                Plate = first(Plate))
    #Flag high cvs
    stds1_Abs2_all_fixed$Abs2_cv_flag <- ifelse(stds1_Abs2_all_fixed$Abs2_cv > cv_flag_stds, 'High CV', 'Within range')
    #bind fixed dataframes back together with non high cv points
    #averaged stds
    stds1_Abs2_all <- subset(stds1_Abs2_all, (!(IDs %in% stds1_Abs2_all_fixed$IDs & Plate %in% stds1_Abs2_all_fixed$Plate)))
    stds1_Abs2_all <- rbind(stds1_Abs2_all_fixed, stds1_Abs2_all) 
    #all points  
    stds_all_fixed <- subset(stds_all_fixed, (!(IDs %in% stds_Abs2_HCV_fixed$IDs & Plate %in% stds_Abs2_HCV_fixed$Plate)))
    stds_all_fixed <- rbind(stds_Abs2_HCV_fixed, stds_all_fixed) 
  }}

# filter High CV Stds
stds_Abs2_HCV <- stds1_Abs2_all %>%  
  filter(str_detect(Abs2_cv_flag, "High CV")) 
head(stds_Abs2_HCV)
```



```{r subset Stds}
#subset by FE_2
FE_2_stds_Abs1 <- stds_all_fixed %>%  
  filter(str_detect(stds_all_fixed$IDs, "Fe_2"))  
head(FE_2_stds_Abs1)
FE_2_stds_Abs2 <- stds_all_fixed %>%  
  filter(str_detect(stds_all_fixed$IDs, "Fe_2")) %>% filter(!(Conc_uM > Top_STD_Fe2_Abs2_high))
head(FE_2_stds_Abs2)
#subset by FE_3
FE_3_stds_Abs1 <- stds_all_fixed %>%  
  filter(str_detect(stds_all_fixed$IDs, "Fe_3"))  
head(FE_3_stds_Abs1)
FE_3_stds_Abs2 <- stds_all_fixed %>%  
  filter(str_detect(stds_all_fixed$IDs, "Fe_3")) %>% filter(!(Conc_uM > Top_STD_Fe3_high)) 
head(FE_3_stds_Abs2)

#subset Fe3 STD with in their linear range

FE_3_stds_high <- FE_3_stds_Abs2

#Subset the low standard curve from all 
FE_2_stds_low <- FE_2_stds_Abs1[!(FE_2_stds_Abs1$Conc_uM > Top_STD_Fe2_low),]
FE_3_stds_low <- FE_3_stds_Abs2[!(FE_3_stds_Abs2$Conc_uM > Top_STD_Fe3_low),]

#subset Fe2 abs2 to 100um 
FE_2_stds_high <-FE_2_stds_Abs1
FE_2_stds_diff<-FE_2_stds_Abs2

```
## Plot standards 
```{r}
#Plot each of these and calculate the slope, intercept, and R2
#Low curve for Fe(II)
FE_2_low <- ggplot(FE_2_stds_low, aes(Conc_uM, Abs1)) + geom_point() + facet_wrap(~Plate)+ geom_smooth(method = "lm", se = FALSE)+ggtitle("Low Fe(II) Absorbance 1 Curve")
FE_2_low

#High curve for Fe2
 FE_2_high <- ggplot(FE_2_stds_Abs1, aes(Conc_uM, Abs1)) + geom_point() + facet_wrap(~Plate)+ geom_smooth(method = "lm", se = FALSE)+ggtitle("High Fe(II) Absorbance 1 Curve")
 FE_2_high
 
 #curve for Fe(II) Abs2
FE_2_abs2 <- ggplot(FE_2_stds_Abs2, aes(Conc_uM, Abs2)) + geom_point() + facet_wrap(~Plate)+ geom_smooth(method = "lm", se = FALSE)+ggtitle("Fe(II) Absorbance 2 Curve")
FE_2_abs2

#curve for Fe(II) Abs2-Abs1
FE_2_stds_diff$FE_2_Diff<-FE_2_stds_diff$Abs2-FE_2_stds_diff$Abs1

FE_2 <- ggplot(FE_2_stds_diff, aes(Conc_uM,FE_2_Diff)) + geom_point() + facet_wrap(~Plate)+ geom_smooth(method = "lm", se = FALSE)+ggtitle("Fe(II) Absorbance Difference Curve")
FE_2

#Low curve for Fe(III)
FE_3_low <- ggplot(FE_3_stds_low, aes(Conc_uM, Abs2)) + geom_point() + facet_wrap(~Plate)+ geom_smooth(method = "lm", se = FALSE)+ggtitle("Low Fe(III) Absorbance 2 Curve")
FE_3_low

#High curve for Fe(III)
FE_3_high <- ggplot(FE_3_stds_high, aes(Conc_uM, Abs2)) + geom_point() + facet_wrap(~Plate)+ geom_smooth(method = "lm", se = FALSE)+ggtitle("High Fe(III) Absorbance 2 Curve")
FE_3_high

#curve for Fe(III) Abs1
FE_3_abs1 <- ggplot(FE_3_stds_Abs1, aes(Conc_uM,Abs1 )) + geom_point() + facet_wrap(~Plate)+ geom_smooth(method = "lm", se = FALSE)+ggtitle("Fe(III) Absorbance 1 Curve")
FE_3_abs1


```


```{r}

###Fe

#Low curve for Fe(II)
FE_2_low_lm <- lm(FE_2_stds_low$Abs1 ~ FE_2_stds_low$Conc_uM)
summary(FE_2_low_lm)
cf <- coef(FE_2_low_lm)

#create data frame with 1 rows and 0 columns
Slopes1 <- data.frame(matrix(ncol = 0, nrow = 1))
Slopes1$Date <- Date_Run
Slopes1$Project <- Project
Slopes1$Curve <- "FE_2_low"
Slopes1$R2 <- summary(FE_2_low_lm)$adj.r.squared
Slopes1$Slope <- cf[2]
Slopes1$Intercept <- cf[1]
Slopes1$Top_STD <- Top_STD_Fe2_low



#High curve for Fe2
 FE_2_high_lm <- lm(FE_2_stds_Abs1$Abs1 ~ FE_2_stds_Abs1$Conc_uM)
 summary(FE_2_high_lm)
 cf <- coef(FE_2_high_lm)
 
#create data frame with 1 rows and 0 columns
Slopes2 <- data.frame(matrix(ncol = 0, nrow = 1))
Slopes2$Date <- Date_Run
Slopes2$Project <- Project
Slopes2$Curve <- "FE_2_high"
Slopes2$R2 <- summary(FE_2_high_lm)$adj.r.squared
Slopes2$Slope <- cf[2]
Slopes2$Intercept <- cf[1]
Slopes2$Top_STD <- Top_STD_Fe2_high

 
#curve for Fe(II) Abs2
FE_2_stds_Abs2_lm <- lm(FE_2_stds_Abs2$Abs2 ~ FE_2_stds_Abs2$Conc_uM)
summary(FE_2_stds_Abs2_lm)
cf <- coef(FE_2_stds_Abs2_lm)

#create data frame with 1 rows and 0 columns
Slopes5 <- data.frame(matrix(ncol = 0, nrow = 1))
Slopes5$Date <- Date_Run
Slopes5$Project <- Project
Slopes5$Curve <- "FE_2_abs2"
Slopes5$R2 <- summary(FE_2_stds_Abs2_lm)$adj.r.squared
Slopes5$Slope <- cf[2]
Slopes5$Intercept <- cf[1]
Slopes5$Top_STD <- Top_STD_Fe2_Abs2_high



#curve for Fe(II) Abs2-Abs1
FE_2_diff_lm <- lm(FE_2_stds_diff$FE_2_Diff ~ FE_2_stds_diff$Conc_uM)
summary(FE_2_diff_lm)
cf <- coef(FE_2_diff_lm)

#create data frame with 1 rows and 0 columns
Slopes7 <- data.frame(matrix(ncol = 0, nrow = 1))
Slopes7$Date <- Date_Run
Slopes7$Project <- Project
Slopes7$Curve <- "FE_2_diff"
Slopes7$R2 <- summary(FE_2_diff_lm)$adj.r.squared
Slopes7$Slope <- cf[2]
Slopes7$Intercept <- cf[1]
Slopes7$Top_STD <- Top_STD_Fe2_Abs2_high


###Fe(3)
#Low curve for Fe(III)
FE_3_low_lm <- lm(FE_3_stds_low$Abs2 ~ FE_3_stds_low$Conc_uM)
summary(FE_3_low_lm)
cf <- coef(FE_3_low_lm)

#create data frame with 1 rows and 0 columns
Slopes3 <- data.frame(matrix(ncol = 0, nrow = 1))
Slopes3$Date <- Date_Run
Slopes3$Project <- Project
Slopes3$Curve <- "FE_Tot_low"
Slopes3$R2 <- summary(FE_3_low_lm)$adj.r.squared
Slopes3$Slope <- cf[2]
Slopes3$Intercept <- cf[1]
Slopes3$Top_STD <- Top_STD_Fe3_low

#High curve for Fe(III) 
FE_3_high_lm <- lm(FE_3_stds_high$Abs2 ~ FE_3_stds_high$Conc_uM)
summary(FE_3_high_lm)
cf <- coef(FE_3_high_lm)
 
 #create data frame with 1 rows and 0 columns
Slopes4 <- data.frame(matrix(ncol = 0, nrow = 1))
Slopes4$Date <- Date_Run
Slopes4$Project <- Project
Slopes4$Curve <- "FE_Tot_high"
Slopes4$R2 <- summary(FE_3_high_lm)$adj.r.squared
Slopes4$Slope <- cf[2]
Slopes4$Intercept <- cf[1]
Slopes4$Top_STD <- Top_STD_Fe3_high

#curve for Fe(III) Abs1
FE_3_abs1_lm <- lm(FE_3_stds_Abs1$Abs1 ~ FE_3_stds_Abs1$Conc_uM )
summary(FE_3_abs1_lm)
cf <- coef(FE_3_abs1_lm)

#create data frame with 1 rows and 0 columns
Slopes6 <- data.frame(matrix(ncol = 0, nrow = 1))
Slopes6$Date <- Date_Run
Slopes6$Project <- Project
Slopes6$Curve <- "FE_3_abs1"
Slopes6$R2 <- summary(FE_3_abs1_lm)$adj.r.squared
Slopes6$Slope <- cf[2]
Slopes6$Intercept <- cf[1]
Slopes6$Top_STD <- Top_STD_Fe2_high


#This slope should be small e-6

Slopes<- rbind(Slopes1, Slopes2, Slopes3, Slopes4, Slopes5, Slopes6, Slopes7)

print(Slopes)
####
```

# Checking STD Data against QAQC file

```{r read in QAQC file}
#read in datafile with all the slopes
qlogO <- read.csv("S:/GlobalChangeEco/porewater_r scripts & Data/BGC_GCE_PorewaterAnalysis/Fe/Fe_STD_QAQC.csv")
qlogO <- qlogO[,c(1:7)]
colnames(qlogO) <- c("Date", "Project", "Curve", "R2", "Slope", "Intercept", "Top_STD")
head(qlogO)

#add data to file
qlog <- rbind(Slopes, qlogO)
head(qlog)

```
```{r check R2}
Rsq1_graph<-function(curve){
  qlog1<-qlog %>% filter(Curve == curve)
Rsq1 <- ggplot(data=qlog1, aes(x=Date, y=R2)) +
  geom_hline(yintercept= (0.98), linetype="dashed", color = "red", size=2)+
  geom_point(aes(size=3)) + 
  theme_classic() + ylim(0.96, 1.01) + 
  theme(legend.position="none")+ 
  ggtitle(paste0(curve," R2"))+
  guides(x = guide_axis(angle = 70))

Rsq1
}
lapply(Slopes$Curve,Rsq1_graph) 
 
#Is the intercept for each plate within 2 standard deviation of the log file? 
for(i in 1:nrow(Slopes)){
  if (Slopes$R2[i] < (r2_cutoff)) {
    ifelse(Slopes$Curve[i]=="FE_3_abs1",print(paste0(Slopes$Curve[i],": R2 will always be low")), print(paste0(Slopes$Curve[i],": Std Curve r2 is below cutoff! - REASSESS")))
  } else {
   print(paste0(Slopes$Curve[i],": Std Curve r2 GOOD"))
  }
  if(!Slopes$Curve[i]=="FE_3_abs1"){
 #writes a flag for Curves that have a low R2   
    dat$QAQC_flag<-if(Slopes$R2[i] <= r2_cutoff){
      ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, "; ",Slopes$Curve[i] ," Std curve r2 low"),paste0(Slopes$Curve[i]," Std curve r2 low"))                   
    }else{
      ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, ""),"")
    }
  }
}


#Rerun if outside of red lines
```

```{r check slopes}
##plot the slopes to make sure there are no crazy outliers 

slope_graph<-function(curve){
  qlog1<-qlog %>% filter(Curve == curve)
slope_Fe <- ggplot(data=qlog1, aes(x=Date, y=Slope)) +
  geom_hline(yintercept= (mean(qlog1$Slope)+ (2*sd(qlog1$Slope))), linetype="dashed", color = "red", size=2)+
  geom_hline(yintercept= (mean(qlog1$Slope)- (2*sd(qlog1$Slope))), linetype="dashed", color = "red", size=2)+
  geom_point(aes(size=3)) + 
  theme_classic() +  
  theme(legend.position="none") + 
  ggtitle( paste0(curve," Slopes"))+
  guides(x = guide_axis(angle = 70))

slope_Fe
}
lapply(Slopes$Curve,slope_graph) 
 
#Is the slope for each plate within 2 standard deviation of the log file? 
for(i in 1:nrow(Slopes)){
  qlog1<-qlog %>% filter(Curve == Slopes$Curve[i])
  if (Slopes$Slope[i] > (mean(qlog1$Slope)+ (2*sd(qlog1$Slope)))| Slopes$Slope[i] < (mean(qlog1$Slope)- (2*sd(qlog1$Slope)))) {
    print(paste0(Slopes$Curve[i],": Std curve slope is 2 sd different from previous slopes! 
      - REASSESS"))
  } else {
    print(paste0(Slopes$Curve[i],":Std curve slope is with 2 sd of previous slopes"))
  }}

#Rerun if outside of red lines
```


```{r check intercepts}
##plot the intercepts to make sure there are no crazy outliers 

intercept_graph<-function(curve){
  qlog1<-qlog %>% filter(Curve == curve)
intercept_Fe <- ggplot(data=qlog1, aes(x=Date, y=Intercept)) +
  geom_hline(yintercept= (mean(qlog1$Intercept)+ (2*sd(qlog1$Intercept))), linetype="dashed", color = "red", size=2)+
  geom_hline(yintercept= (mean(qlog1$Intercept)- (2*sd(qlog1$Intercept))), linetype="dashed", color = "red", size=2)+
  geom_point(aes(size=3)) + 
  theme_classic() +  
  theme(legend.position="none") + 
  ggtitle( paste0(curve," Intercepts"))+
  guides(x = guide_axis(angle = 70))

intercept_Fe
}
lapply(Slopes$Curve,intercept_graph) 
 
#Is the intercept for each plate within 2 standard deviation of the log file? 
for(i in 1:nrow(Slopes)){
  qlog1<-qlog %>% filter(Curve == Slopes$Curve[i])
  if (Slopes$Intercept[i] > (mean(qlog1$Intercept)+ (2*sd(qlog1$Intercept)))| Slopes$Intercept[i] < (mean(qlog1$Intercept)- (2*sd(qlog1$Intercept)))) {
    print(paste0(Slopes$Curve[i],":Std curve intercept is 2 sd different from previous intercepts! 
      - REASSESS"))
  } else {
    print(paste0(Slopes$Curve[i],":Std curve intercept is with 2 sd of previous intercepts"))
  }}

#Rerun if outside of red lines
```


## Calculate Reduction Efficiency 
```{r}
#pull out Fe_2 and Fe_3 standards at 60uM to check reduction efficiency

#subset by FE_2 and FE_Total
FE_2_60uM <- stds %>%  
  filter(str_detect(stds$IDs, "60 uM Fe_2 A"))  
head(FE_2_60uM)

#subset by FE_2 and FE_Total
FE_3_60uM <- stds %>%  
  filter(str_detect(IDs, "60 uM Fe_3 A"))  
head(FE_3_60uM)


#create data frame with 0 rows and 3 columns
Fe_Red_eff <- data.frame(matrix(ncol = 0, nrow = 3))

Fe_Red_eff$ID <- FE_2_60uM$Wells
Fe_Red_eff$FE2 <- (FE_2_60uM$Abs1)
Fe_Red_eff$FE3 <- FE_3_60uM$Abs2
Fe_Red_eff$Eff <- ((Fe_Red_eff$FE3)/Fe_Red_eff$FE2)*100
Fe_Red_eff$Eff1 <- ((Fe_Red_eff$FE3/0.8)/Fe_Red_eff$FE2)*100 #this one accounts for dilution of the reagents 
head(Fe_Red_eff)

Fe_Red_eff$Eff_flag <-  ifelse(Fe_Red_eff$Eff1 > low_recovery_cutoff & Fe_Red_eff$Eff1 < high_recovery_cutoff, 'OK', 'NO, rerun')  

#plot spk recoveries output as a bar graph to easily check - want any over 10% to be red need to work on this 
redeffbar <- ggplot(data = Fe_Red_eff, aes(x = ID, y = Eff1,fill=Eff_flag)) +
        geom_bar(stat = 'identity') + 
        scale_fill_manual(values=c("OK"="darkgreen","NO, rerun"="darkred")) + 
        theme_classic() + labs(x= "Sample ID", y="Reduction Efficiency (%)") + 
        theme(legend.position="none") +  
        geom_hline(yintercept=low_recovery_cutoff, linetype="dashed", color = "black", size=1) + 
        geom_hline(yintercept=high_recovery_cutoff, linetype="dashed", color = "black", size=1)

redeffbar


BadEff <- subset(Fe_Red_eff, Eff_flag == "NO, rerun")

#write out a flag to the sample dataframe if any spks have recovery out of range 

dat$QAQC_flag<-if(nrow(BadEff) > 0){
  iifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, "; Reduction Efficiency out of range"),"Reduction Efficiency out of range")                   
  }else{
    ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, ""),"")
}


Eff_percent <- (sum(Fe_Red_eff$Eff_flag == "OK")/nrow(Fe_Red_eff))*100
#report out if flags indicate need for rerun
ifelse(Eff_percent >= 60  , ">60% of Reduction Efficiencies are within range",
       "<60% of Reduction Efficiencies are out of range - REASSESS")


```

## Method Minimum Detection Limit (MDL) Calculation
I use the lowest standard to calculate MDL
How to calculate MDL https://www.epa.gov/sites/default/files/2016-12/documents/mdl-procedure_rev2_12-13-2016.pdf
Look at Table 1 on page 5
The Student's t-value used to calculate the method detection limit (MDL) is the one appropriate for a 99% confidence level and a standard deviation estimate with n-1 degrees of freedom


##need to ask Alia or steph why
```{r}
#make a dataframe of just 0.6 uM Fe2 samples from standard dataframe
MDL_dat <- subset(FE_2_stds_Abs1, Conc_uM == 0)

#calculate the standard deviation of abs 1
stddev <- sd(MDL_dat$Abs1)

#calculate n (number of 0.6 uM samples)
n <- nrow(MDL_dat)

#Identify the proper Student's T for n-1 from the table link above
StudentsT <- 3.143

#Multiply Standard deviation by Student's T
MDL <- stddev*StudentsT+mean(MDL_dat$Abs1)
MDL
```


## Check standards QAQC

```{r}
Fe2_low <- subset(Slopes, Curve == "FE_2_low")
Fe2_high <- subset(Slopes, Curve == "FE_2_high")
FeTot_low <- subset(Slopes, Curve == "FE_Tot_low")
FeTot_high <- subset(Slopes, Curve == "FE_Tot_high")
Fe2_abs2 <- subset(Slopes, Curve == "FE_2_abs2")
Fe3_abs1 <- subset(Slopes, Curve == "FE_3_abs1")
Fe2_diff <- subset(Slopes, Curve == "FE_2_diff")

QAstdchk<-data.frame(matrix(nrow=0,ncol=3))
        colnames(QAstdchk) <- c("Plate","IDs","p_value")

#Make sure check standards are not different from standard concentration
#subset Check Standards from the rest of the dataset
Fe2_std_Chk <- dat %>%  filter(str_detect(IDs, "Fe_2"))
Fe3_std_Chk <- dat %>%  filter(str_detect(IDs, "Fe_3"))

#Calculate Check standard Concentration
Fe2_std_Chk$Conc_uM <- (Fe2_std_Chk$Abs1-Fe2_low$Intercept)/Fe2_low$Slope
Fe3_std_Chk$Conc_uM <-(Fe3_std_Chk$Abs2-FeTot_low$Intercept)/FeTot_low$Slope


#Are the check standards significantly different from the standards?
#subset datasets for comparison
Fe2_std0.6 <- subset(FE_2_stds_low, Conc_uM == 0.6)
Fe2_std9 <- subset(FE_2_stds_low, Conc_uM == 9.0)
Fe2_std60 <- subset(FE_2_stds_low, Conc_uM == 60.0)

Fe3_std0.6 <- subset(FE_3_stds_low, Conc_uM == 0.6)
Fe3_std9 <- subset(FE_3_stds_low, Conc_uM == 9.0)
Fe3_std60 <- subset(FE_3_stds_low, Conc_uM == 60.0)


for(i in 1:length(plates)){
  Fe2_std_Chk1<-filter(Fe2_std_Chk, Plate %in% plates[i])
  Fe3_std_Chk1<-filter(Fe3_std_Chk, Plate %in% plates[i])
print(plates[i])

Fe2_Chkstd0.6 <- subset(Fe2_std_Chk1, IDs %like% "0.6")
Fe2_Chkstd9 <- subset(Fe2_std_Chk1, IDs %like% "9")
Fe2_Chkstd60 <- subset(Fe2_std_Chk1, IDs %like% "60")
Fe3_Chkstd0.6 <- subset(Fe3_std_Chk1, IDs %like% "0.6")
Fe3_Chkstd9 <- subset(Fe3_std_Chk1, IDs %like% "9")
Fe3_Chkstd60 <- subset(Fe3_std_Chk1, IDs %like% "60")


if(!nrow(Fe2_std0.6) == 0 & !nrow(Fe2_Chkstd0.6) == 0){
Fe2.t.test.std0.6 <- t.test(Fe2_std0.6$Abs1,Fe2_Chkstd0.6$Abs1,var.equal = T)
Fe2.t.test.std0.6

if(Fe2.t.test.std0.6$p.value > p_value_chkstds){
print("Fe2 Chk Std 0.6 GOOD")
} else {
print("Fe2 Chk Std 0.6 is signficantly different from Std - REASSESS")
}
#write out a flag to the sample dataframe if the Chk std is Bad
  dat$QAQC_flag<-if(Fe2.t.test.std0.6$p.value < p_value_chkstds){
    ifelse(dat$Plate %in% plates[i], ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, "; Fe2 Chk Std 0.6 out of range"),"Fe2 Chk Std 0.6 out of range"),paste0( dat$QAQC_flag,"") )                   
  }else{
    ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, ""),"")
  } 
#Add p-values to dataframes
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 0.6 Fe2",p_value=Fe2.t.test.std0.6$p.value)) 
}else{
  #if std didn't have enough points for t-test
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 0.6 Fe2",p_value=NA)) 
  print("Std excluded")
}

if(!nrow(Fe2_std9) == 0 & !nrow(Fe2_Chkstd9) == 0){
Fe2.t.test.std9 <- t.test(Fe2_std9$Abs1,Fe2_Chkstd9$Abs1,var.equal = T)
Fe2.t.test.std9

if(Fe2.t.test.std9$p.value > p_value_chkstds){
print("Fe2 Chk Std 9 GOOD")
} else {
print("Fe2 Chk Std 9 is signficantly different from Std - REASSESS")
}
#write out a flag to the sample dataframe if the Chk std is Bad
  dat$QAQC_flag<-if(Fe2.t.test.std9$p.value < p_value_chkstds){
    ifelse(dat$Plate %in% plates[i], ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, "; Fe2 Chk Std 9 out of range"),"Fe2 Chk Std 9 out of range"),paste0( dat$QAQC_flag,"") )                   
  }else{
    ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, ""),"")
  } 
#Add p-values to dataframes
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 9 Fe2",p_value=Fe2.t.test.std9$p.value)) 
}else{
  #if std didn't have enough points for t-test
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 9 Fe2",p_value=NA)) 
  print("Std excluded")
}

if(!nrow(Fe2_std60) == 0 & !nrow(Fe2_Chkstd60) == 0){
Fe2.t.test.std60 <- t.test(Fe2_std60$Abs1,Fe2_Chkstd60$Abs1,var.equal = T)
Fe2.t.test.std60

if(Fe2.t.test.std60$p.value > p_value_chkstds){
print("Fe2 Chk Std 60 GOOD")
} else {
print("Fe2 Chk Std 60 is signficantly different from Std - REASSESS")
}
#write out a flag to the sample dataframe if the Chk std is Bad
  dat$QAQC_flag<-if(Fe2.t.test.std60$p.value < p_value_chkstds){
    ifelse(dat$Plate %in% plates[i], ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, "; Fe2 Chk Std 60 out of range"),"Fe2 Chk Std 60 out of range"),paste0( dat$QAQC_flag,"") )                   
  }else{
    ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, ""),"")
  } 
#Add p-values to dataframes
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 60 Fe2",p_value=Fe2.t.test.std60$p.value)) 
}else{
  #if std didn't have enough points for t-test
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 60 Fe2",p_value=NA)) 
  print("Std excluded")
}

if(!nrow(Fe3_std0.6) == 0 & !nrow(Fe3_Chkstd0.6) == 0){
Fe3.t.test.std0.6 <- t.test(Fe3_std0.6$Abs2,Fe3_Chkstd0.6$Abs2,var.equal = T)
Fe3.t.test.std0.6

if(Fe3.t.test.std0.6$p.value > p_value_chkstds){
print("Fe 3 Chk Std 0.6 Fe2 GOOD")
} else {
print("Fe 3 Chk Std 0.6 is signficantly different from Std - REASSESS")
}
#write out a flag to the sample dataframe if the Chk std is Bad
  dat$QAQC_flag<-if(Fe3.t.test.std0.6$p.value < p_value_chkstds){
    ifelse(dat$Plate %in% plates[i], ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, "; Fe3 Chk Std 0.6 out of range"),"Fe3 Chk Std 0.6 out of range"),paste0( dat$QAQC_flag,"") )                   
  }else{
    ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, ""),"")
  } 
#Add p-values to dataframes
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 0.6 Fe3",p_value=Fe3.t.test.std0.6$p.value)) 
}else{
  #if std didn't have enough points for t-test
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 0.6 Fe3",p_value=NA)) 
  print("Std excluded")
}

if(!nrow(Fe3_std9) == 0 & !nrow(Fe3_Chkstd9) == 0){
Fe3.t.test.std9 <- t.test(Fe3_std9$Abs2,Fe3_Chkstd9$Abs2,var.equal = T)
Fe3.t.test.std9

if(Fe3.t.test.std9$p.value > p_value_chkstds){
print("Fe 3 Chk Std 9 GOOD")
} else {
print("Fe 3 Chk Std 9 is signficantly different from Std - REASSESS")
}
#write out a flag to the sample dataframe if the Chk std is Bad
  dat$QAQC_flag<-if(Fe3.t.test.std9$p.value < p_value_chkstds){
    ifelse(dat$Plate %in% plates[i], ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, "; Fe3 Chk Std 9 out of range"),"Fe3 Chk Std 9 out of range"),paste0( dat$QAQC_flag,"") )                   
  }else{
    ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, ""),"")
  } 
#Add p-values to dataframes
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 9 Fe3",p_value=Fe3.t.test.std9$p.value)) 
}else{
  #if std didn't have enough points for t-test
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 9 Fe3",p_value=NA)) 
  print("Std excluded")
}

if(!nrow(Fe3_std60) == 0 & !nrow(Fe3_Chkstd60) == 0){
Fe3.t.test.std60 <- t.test(Fe3_std60$Abs2,Fe3_Chkstd60$Abs2,var.equal = T)
Fe3.t.test.std60

if(Fe3.t.test.std60$p.value > p_value_chkstds){
print("Fe 3 Chk Std 60 GOOD")
} else {
print("Fe 3 Chk Std 60 is signficantly different from Std - REASSESS")
}
#write out a flag to the sample dataframe if the Chk std is Bad
  dat$QAQC_flag<-if(Fe3.t.test.std60$p.value < p_value_chkstds){
    ifelse(dat$Plate %in% plates[i], ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, "; Fe3 Chk Std 60 out of range"),"Fe3 Chk Std 60 out of range"),paste0( dat$QAQC_flag,"") )                   
  }else{
    ifelse(dat$QAQC_flag != "", paste0(dat$QAQC_flag, ""),"")
  } 
#Add p-values to dataframes
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 60 Fe3",p_value=Fe3.t.test.std60$p.value)) 
}else{
  #if std didn't have enough points for t-test
  QAstdchk<-rbind(QAstdchk,list(Plate=plates[i],IDs="Std 60 Fe3",p_value=NA)) 
  print("Std excluded")
}
}

#flag p-values
QAstdchk$p_flag <-  ifelse(QAstdchk$p_value > p_value_chkstds, 'OK', 'Rerun')

#plot output as a bar graph to easily check
ChkStdbar <- ggplot(data = QAstdchk, aes(x = IDs, y = p_value, fill=p_flag))+
        facet_wrap(~Plate)+
        geom_bar(stat = 'identity') + 
        scale_fill_manual(values = c("OK" = "darkgreen", "Rerun" = "darkred"))+
        theme_classic() + labs(x= "Sample ID", y="T-test p-value") + 
        theme(legend.position="none") +  geom_hline(yintercept=0.05, linetype="dashed", 
                color = "black", linewidth=1)+ 
        ggtitle("Check Standards")

ChkStdbar
```

#No Matrix Checks
We do not use matrix checks for the Fe samples because our matrix checks are not made with Trace metal grade reagents. If we want to do this in the future, we need to use trace metal grade sodium chloride and sodium bicarbonate for making the matrix checks

```{r flag out of range data}

## remove any lines that say stds in IDs
dat1 <- dat %>%  filter(!str_detect(IDs, "Fe_2"))
head(dat1)
dat1 <- dat1 %>%  filter(!str_detect(IDs, "Fe_3"))
head(dat1)
dat1 <- dat1 %>%  filter(!str_detect(IDs, "HCl"))
head(dat1)


#Now flag any Abs1 that are above the 500uM standard absorbance
FE_2_500uM<- FE_2_stds_high %>%  filter(Conc_uM == Top_STD_Fe2_high)

dat1$FE_2_Curve <- ifelse(dat1$Abs1 > mean(FE_2_500uM$Abs1), "High", "Within range")

#and flag any that are below the MDL
dat1$FE_2_Curve <- ifelse(dat1$Abs1 < MDL, "Below MDL", dat1$FE_2_Curve)



#Now flag any Abs2 that are above the 500uM standard absorbance
FE_2_100uM<- FE_2_stds_Abs2 %>%  filter(Conc_uM == Top_STD_Fe2_Abs2_high)
FE_3_100uM<- FE_3_stds_Abs2 %>%  filter(Conc_uM == Top_STD_Fe3_high)

dat1$FE_Tot_Curve <- ifelse(dat1$Abs2 > mean(FE_2_100uM$Abs2), "High", ifelse((dat1$Abs2-dat1$Abs1) > mean(FE_3_100uM$Abs2), "High", "Within range")) 

#and flag any that are below the MDL
dat1$FE_Tot_Curve <- ifelse(dat1$Abs2 < MDL, "Below MDL", dat1$FE_Tot_Curve)


head(dat1)

#Make a list of samples to dilute and rerun
Fe_DiluteRerun <- subset(dat1, FE_2_Curve == "High"|FE_Tot_Curve == "High")

```

## Subset Data and Calculate Concentrations 
```{r}
###Calculate concentrations of Fe(II)
dat1$FE_2_Conc <- ifelse(dat1$Abs1 > mean(Fe2_std60$Abs1), (dat1$Abs1-Fe2_high$Intercept)/Fe2_high$Slope, (dat1$Abs1-Fe2_low$Intercept)/Fe2_low$Slope)

head(dat1)
#Calculate the expected absorbance 2 for just Fe 2
#Expected_diff=m*conc+b
### abs2=abs1+diff
dat1$CalcAbs2<-dat1$Abs1+(dat1$FE_2_Conc*Fe2_diff$Slope+Fe2_diff$Intercept)

#subtract expected absorbance from actual absorbance this should leave you with the absorbance caused by the Fe3 reducing to Fe2
dat1$Abs2_diff<-dat1$Abs2-dat1$CalcAbs2

#using the slope from Fe 2 slope calculate Fe3 
dat1$FE_3_Conc <-ifelse(dat1$Abs2 > mean(Fe3_std60$Abs2), (dat1$Abs2_diff)/(FeTot_high$Slope-Fe3_abs1$Slope), (dat1$Abs2_diff)/(FeTot_low$Slope-Fe3_abs1$Slope))


head(dat1)
```
```{r}

#Account for the dilution factor
dat1$FE_2_Conc_DilCorr <- dat1$FE_2_Conc*dat1$Dilution

dat1$FE_3_Conc_DilCorr <- (dat1$FE_3_Conc*dat1$Dilution)

head(dat1)

#Use ifelse to make any negative values equal to zero 
dat1$FE_2_Conc_Final <- ifelse(dat1$FE_2_Conc_DilCorr <0, 0, dat1$FE_2_Conc_DilCorr)

dat1$FE_3_Conc_Final <- ifelse(dat1$FE_3_Conc_DilCorr <0, 0, dat1$FE_3_Conc_DilCorr)

head(dat1)

```
## Calculate Averages across wells, std. dev, and cv.  
```{r}
dat_aver<-data.frame(matrix(nrow=0,ncol=17))
colnames(dat_aver)<-colnames(dat1)
for(i in 1:length(plates)){
#summarize by sampleID so that we can calculate the mean and std. dev. of the three wells 
dat2<- dat1 %>% filter(Plate== plates[i]) 
dat2 <- dat2 %>%
  group_by(IDs) %>%
  summarise(FE_2_mean = mean(FE_2_Conc_Final), FE_2_sd = sd(FE_2_Conc_Final), FE_2_cv = cv(FE_2_Conc_Final),
            FE_3_mean = mean(FE_3_Conc_Final), FE_3_sd = sd(FE_3_Conc_Final), FE_3_cv = cv(FE_3_Conc_Final),
            FE_2_flag = first(FE_2_Curve), FE_3_flag = first(FE_Tot_Curve), 
            Dilution = first(Dilution), 
            Plate = first(Plate), 
            QAQC_flag = first(QAQC_flag))

head(dat2)

dat2$FE_2_cv_flag <- ifelse(dat2$FE_2_cv > 10, "High cv rerun", "ok")
dat2$FE_3_cv_flag <- ifelse(dat2$FE_3_cv > 10, "High cv rerun", "ok")


dat_aver<-rbind(dat_aver,dat2)
}

#Make a list of samples to rerun
HighCVSamples <- subset(dat_aver, FE_2_cv_flag == "High cv rerun"|FE_3_cv_flag == "High cv rerun")
HighCVSamplesFe2 <- subset(dat_aver, FE_2_cv_flag == "High cv rerun")
HighCVSamplesFe3 <- subset(dat_aver, FE_3_cv_flag == "High cv rerun")

Fe2 <- ggplot(dat_aver, aes(x=IDs, y=FE_2_mean))+ 
  geom_point(size=4) +  theme_classic() + facet_grid(~Plate)+
  labs(y="Fe(II) (uM)", x="Sample ID")+
  guides(x = guide_axis(angle = 70)) + 
  geom_errorbar(aes(ymin=FE_2_mean-FE_2_sd,
                    ymax=FE_2_mean+FE_2_sd),width=0.3,position=position_dodge(.1))
Fe2

Fe3 <- ggplot(dat_aver, aes(x=IDs, y=FE_3_mean))+ 
  geom_point(size=4) +  theme_classic() + facet_grid(~Plate)+
  labs(y="Fe(III) (uM)", x="Sample ID")+
  guides(x = guide_axis(angle = 70)) + 
  geom_errorbar(aes(ymin=FE_3_mean-FE_3_sd,
                    ymax=FE_3_mean+FE_3_sd),width=0.3,position=position_dodge(.1))
Fe3
```
## Remove bad reps
```{r}
dat_aver1<-data.frame(matrix(nrow=0,ncol=14))
colnames(dat_aver1)<-colnames(dat_aver1)

for(i in 1:length(plates)){
#summarize by sampleID so that we can calculate the mean and std. dev. of the three wells 
dat_aver2<- dat_aver %>% filter(Plate== plates[i]) 
#auto remove bad reps
dat_HCV <- subset(dat1, (IDs %in% HighCVSamples$IDs & Plate %in% plates[i]))
head(dat_HCV)
HighCVSamples_loop<-subset(HighCVSamples, Plate %in% plates[i])
#Columns 4 7 10
Column1= c("A04", "A07","A10", "B04", "B07", "B10" ,"C04" , "C07", "C10",
"D04", "D07", "D10", "E04","E07", "E10" ,"F04" , "F07" ,"F10", "G04","G07" ,"G10" ,"H04","H07","H10")

#Columns 5,8,11
Column2= c("A05", "A08","A11", "B05", "B08", "B11" ,"C05" , "C08", "C11",
"D05","D08", "D11", "E05","E08", "E11" ,"F05" , "F08", "F11" ,"G05","G08" ,"G11" ,"H05","H08", "H11")

#Columns 6,9,12
Column3= c("A06", "A09","A12", "B06", "B09" ,"B12" ,"C06" , "C09", "C12",
"D06","D09", "D12", "E06","E09", "E12" ,"F06" , "F09", "F12" ,"G06","G09" ,"G12" ,"H06","H09", "H12")


#delete Column one
dat_HCV1 <- subset(dat_HCV, !(Wells %in% Column1 ))
#delete Column two
dat_HCV2 <- subset(dat_HCV, !(Wells %in% Column2 ))
#delete Column three
dat_HCV3 <- subset(dat_HCV, !(Wells %in% Column3 ))

##Find CV for each Data set
#W/out column1
dat_HCV1 <- dat_HCV1 %>%
  group_by(IDs) %>%
  summarise(FE_2_mean = mean(FE_2_Conc_Final), FE_2_sd = sd(FE_2_Conc_Final), FE_2_cv = cv(FE_2_Conc_Final),
            FE_3_mean = mean(FE_3_Conc_Final), FE_3_sd = sd(FE_3_Conc_Final), FE_3_cv = cv(FE_3_Conc_Final),
            FE_2_flag = first(FE_2_Curve),
            FE_3_flag = first(FE_Tot_Curve),
            Dilution = first(Dilution),              
            Plate = first(Plate),              
            QAQC_flag = first(QAQC_flag))
dat_HCV1$FE_2_cv_flag <- ifelse(dat_HCV1$FE_2_cv > 10, 'High CV', 'within range')
dat_HCV1$FE_3_cv_flag <- ifelse(dat_HCV1$FE_3_cv > 10, 'High CV', 'within range')
#W/out column2
dat_HCV2 <- dat_HCV2 %>%
  group_by(IDs) %>%
  summarise(FE_2_mean = mean(FE_2_Conc_Final), FE_2_sd = sd(FE_2_Conc_Final), FE_2_cv = cv(FE_2_Conc_Final),
            FE_3_mean = mean(FE_3_Conc_Final), FE_3_sd = sd(FE_3_Conc_Final), FE_3_cv = cv(FE_3_Conc_Final),
            FE_2_flag = first(FE_2_Curve),
            FE_3_flag = first(FE_Tot_Curve),
            Dilution = first(Dilution),              
            Plate = first(Plate),              
            QAQC_flag = first(QAQC_flag))
dat_HCV2$FE_2_cv_flag <- ifelse(dat_HCV2$FE_2_cv > 10, 'High CV', 'within range')
dat_HCV2$FE_3_cv_flag <- ifelse(dat_HCV2$FE_3_cv > 10, 'High CV', 'within range')
#W/out column3
dat_HCV3 <- dat_HCV3 %>%
  group_by(IDs) %>%
  summarise(FE_2_mean = mean(FE_2_Conc_Final), FE_2_sd = sd(FE_2_Conc_Final), FE_2_cv = cv(FE_2_Conc_Final),
            FE_3_mean = mean(FE_3_Conc_Final), FE_3_sd = sd(FE_3_Conc_Final), FE_3_cv = cv(FE_3_Conc_Final),
            FE_2_flag = first(FE_2_Curve),
            FE_3_flag = first(FE_Tot_Curve),
            Dilution = first(Dilution),
            Plate = first(Plate),
            QAQC_flag = first(QAQC_flag))
dat_HCV3$FE_2_cv_flag <- ifelse(dat_HCV3$FE_2_cv > 10, 'High CV', 'within range')
dat_HCV3$FE_3_cv_flag <- ifelse(dat_HCV3$FE_3_cv > 10, 'High CV', 'within range')

#find lowest CVs
dat_HCV1_Fe2 <- subset(dat_HCV1, dat_HCV1$FE_2_cv < dat_HCV2$FE_2_cv & dat_HCV1$FE_2_cv < dat_HCV3$FE_2_cv)
head(dat_HCV1_Fe2)
dat_HCV1_Fe3 <- subset(dat_HCV1, dat_HCV1$FE_3_cv < dat_HCV2$FE_3_cv & dat_HCV1$FE_3_cv < dat_HCV3$FE_3_cv)
head(dat_HCV1_Fe3)

dat_HCV2_Fe2 <- subset(dat_HCV2, dat_HCV2$FE_2_cv < dat_HCV1$FE_2_cv & dat_HCV2$FE_2_cv < dat_HCV3$FE_2_cv)
head(dat_HCV2_Fe2)
dat_HCV2_Fe3 <- subset(dat_HCV2, dat_HCV2$FE_3_cv < dat_HCV1$FE_3_cv & dat_HCV2$FE_3_cv < dat_HCV3$FE_3_cv)
head(dat_HCV2_Fe3)

dat_HCV3_Fe2 <- subset(dat_HCV3, dat_HCV3$FE_2_cv < dat_HCV1$FE_2_cv & dat_HCV3$FE_2_cv < dat_HCV2$FE_2_cv)
head(dat_HCV3_Fe2)
dat_HCV3_Fe3 <- subset(dat_HCV3, dat_HCV3$FE_3_cv < dat_HCV1$FE_3_cv & dat_HCV3$FE_3_cv < dat_HCV2$FE_3_cv)
head(dat_HCV3_Fe3)

#recombine data frames
HCV_Fe2_recalc <- rbind(dat_HCV1_Fe2, dat_HCV2_Fe2, dat_HCV3_Fe2)
HCV_Fe3_recalc <- rbind(dat_HCV1_Fe3, dat_HCV2_Fe3, dat_HCV3_Fe3)

#order the dataframes and make sure sample lists are the same size
HighCVSamples1<-HighCVSamples_loop[order(HighCVSamples_loop$IDs),]
HighCVSamplesFe2_1 <-subset(HighCVSamples1, (!IDs %in% HCV_Fe2_recalc$IDs ))
HighCVSamplesFe2_1 <- rbind(HCV_Fe2_recalc, HighCVSamplesFe2_1 )
HighCVSamplesFe2_1 <-HighCVSamplesFe2_1[order(HighCVSamplesFe2_1$IDs),]

HighCVSamples1<-HighCVSamples_loop[order(HighCVSamples_loop$IDs),]
HighCVSamplesFe3_1 <-subset(HighCVSamples1, (!IDs %in% HCV_Fe3_recalc$IDs ))
HighCVSamplesFe3_1 <- rbind(HighCVSamplesFe3_1, HCV_Fe3_recalc)
HighCVSamplesFe3_1 <-HighCVSamplesFe3_1[order(HighCVSamplesFe3_1$IDs),]


#correct mean, sd, cv for combined Fe2 and Fe3
HighCVSamples1$FE_2_mean <- ifelse(HighCVSamples_loop$IDs %in% HighCVSamplesFe2$IDs, HighCVSamplesFe2_1$FE_2_mean,HighCVSamples_loop$FE_2_mean)
HighCVSamples1$FE_2_sd <- ifelse(HighCVSamples_loop$IDs %in% HighCVSamplesFe2$IDs, HighCVSamplesFe2_1$FE_2_sd, HighCVSamples_loop$FE_2_sd )
HighCVSamples1$FE_2_cv <- ifelse(HighCVSamples_loop$IDs %in% HighCVSamplesFe2$IDs, HighCVSamplesFe2_1$FE_2_cv,HighCVSamples_loop$FE_2_cv )

HighCVSamples1$FE_3_mean <- ifelse(HighCVSamples_loop$IDs %in% HighCVSamplesFe3$IDs, HighCVSamplesFe3_1$FE_3_mean,HighCVSamples1$FE_3_mean )
HighCVSamples1$FE_3_sd <- ifelse(HighCVSamples_loop$IDs %in% HighCVSamplesFe3$IDs, HighCVSamplesFe3_1$FE_3_sd,HighCVSamples1$FE_3_sd )
HighCVSamples1$FE_3_cv <- ifelse(HighCVSamples_loop$IDs %in% HighCVSamplesFe3$IDs, HighCVSamplesFe3_1$FE_3_cv,HighCVSamples1$FE_3_cv )

#rerun CV flag
HighCVSamples1$FE_2_cv_flag <- ifelse(HighCVSamples1$FE_2_cv > 10, "High cv rerun", "ok")
HighCVSamples1$FE_3_cv_flag <- ifelse(HighCVSamples1$FE_3_cv > 10, "High cv rerun", "ok")

#recombine corrected means with original data
dat_aver2 <- subset(dat_aver2, (!IDs %in% HighCVSamples1$IDs ))
dat_aver2 <- rbind(HighCVSamples1, dat_aver2)

dat_aver1<-rbind(dat_aver1,dat_aver2)
}
Fe2 <- ggplot(dat_aver1, aes(x=IDs, y=FE_2_mean))+ 
  geom_point(size=4) +  theme_classic() + facet_grid(~Plate)+
  labs(y="Fe(II) (uM)", x="Sample ID")+
  guides(x = guide_axis(angle = 70)) + 
  geom_errorbar(aes(ymin=FE_2_mean-FE_2_sd,
                    ymax=FE_2_mean+FE_2_sd),width=0.3,position=position_dodge(.1))
Fe2

Fe3 <- ggplot(dat_aver1, aes(x=IDs, y=FE_3_mean))+ 
  geom_point(size=4) +  theme_classic() + facet_grid(~Plate)+
  labs(y="Fe(III) (uM)", x="Sample ID")+
  guides(x = guide_axis(angle = 70)) + 
  geom_errorbar(aes(ymin=FE_3_mean-FE_3_sd,
                    ymax=FE_3_mean+FE_3_sd),width=0.3,position=position_dodge(.1))
Fe3

#Make a list of samples to rerun
HighCVSamples2 <- subset(dat_aver1, FE_2_cv_flag == "High cv rerun"|FE_3_cv_flag == "High cv rerun")

write.csv(dat_aver1, "S:/GlobalChangeEco/Porewater_R scripts & Data/Data/Fe/COMPASS/TEMPEST Aquifer Well/QAQC'd Data/TEMPEST_AquiferWell_data.csv")
write.csv(dat1, "S:/GlobalChangeEco/Porewater_R scripts & Data/Data/Fe/COMPASS/TEMPEST Aquifer Well/QAQC'd Data/TEMPEST_AquiferWell_Fulldata.csv")
```




